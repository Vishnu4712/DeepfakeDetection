{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "curr_path=os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading all fake videos contaning folders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_folders=[os.path.join(curr_path,file) for file in os.listdir(curr_path) if file.endswith(\"fake\")]\n",
    "fake_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading all real videos contaning folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\kleos_dataset\\\\real\\\\celeb_df_real',\n",
       " 'c:\\\\kleos_dataset\\\\real\\\\cropped_celeb_df_real',\n",
       " 'c:\\\\kleos_dataset\\\\real\\\\dfdc_cropped_real',\n",
       " 'c:\\\\kleos_dataset\\\\real\\\\dfdc_real']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_folders=[os.path.join(curr_path,file) for file in os.listdir(curr_path) if file.endswith(\"real\")]\n",
    "real_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading all types of dataset(celeb df and dfdc) of fake videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_df_fake_vids=[os.path.join(fake_folders[0],vid) for vid in os.listdir(fake_folders[0]) if vid.endswith(\".mp4\")]\n",
    "dfdc_fake_vids=[os.path.join(fake_folders[1],vid) for vid in os.listdir(fake_folders[1]) if vid.endswith(\".mp4\")]\n",
    "total_fake_vids=len(celeb_df_fake_vids)+len(dfdc_fake_vids)\n",
    "total_fake_vids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading all types of dataset(celeb df and dfdc) of real videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_df_real_vids=[os.path.join(real_folders[0],vid) for vid in os.listdir(real_folders[0]) if vid.endswith(\".mp4\")]\n",
    "celeb_df_real_vids\n",
    "dfdc_real_vids=[os.path.join(real_folders[3],vid) for vid in os.listdir(real_folders[3]) if vid.endswith(\".mp4\")]\n",
    "total_real_vids=len(celeb_df_real_vids)+len(dfdc_real_vids)\n",
    "total_real_vids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame extraction and saving in json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_frames(video_path,output_dir):\n",
    "    # print(\"for video\",video_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Unable to open video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # print(total_frames,frame_rate)\n",
    "    # print(\"duration\",total_frames/frame_rate)\n",
    "\n",
    "    #nor of continuous frames to group together)\n",
    "    group_size = 8\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for i in range(0, total_frames - group_size + 1, group_size):\n",
    "        frames = []\n",
    "        for j in range(group_size):\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                frames.append(frame)\n",
    "            else:\n",
    "                print(f\"Error reading frame {i + j} from video {video_path}\")\n",
    "                break\n",
    "\n",
    "        if len(frames) < group_size:  #if total frames not divisible by 8 ignore the ending frames\n",
    "\n",
    "            break\n",
    "\n",
    "        sample = {\n",
    "            'video_path': video_path,\n",
    "            'frame_range': (i + 1, i + group_size) \n",
    "        }\n",
    "        samples.append(sample)\n",
    "    \n",
    "    # print(samples)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    json_filename = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}.json\")\n",
    "    \n",
    "    with open(json_filename, 'w') as json_file:\n",
    "        json.dump(samples, json_file, indent=4)\n",
    "    \n",
    "    print(f\"Saved {len(samples)} samples to {json_filename}\")\n",
    "\n",
    "output_dir=os.path.join((os.getcwd()),\"celeb_df_real_json_files\")\n",
    "for vid in celeb_df_real_vids:\n",
    "   extract_video_frames(vid,output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to crop faces from videos using yolo-v8 followed by openCV built-in object tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_tracker(filename, model,output_path):\n",
    "    # print(filename)\n",
    "    video = cv2.VideoCapture(filename)  \n",
    "    tracker = None  \n",
    "    detection_duration = 4  \n",
    "    start_time = time.time()  \n",
    "\n",
    "    # frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    # frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    req_resolution=(224,224)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, req_resolution)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read() \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if tracker is None:\n",
    "            results = model(frame)\n",
    "            if results and len(results) > 0:\n",
    "                bboxes = results[0].boxes  \n",
    "\n",
    "                if len(bboxes) > 0:\n",
    "                    bbox = bboxes[0]\n",
    "                    last_bbox = bbox  \n",
    "                    x1, y1, x2, y2 = tuple(map(int, bbox.xyxy[0]))\n",
    "                    w = x2 - x1 \n",
    "                    h = y2 - y1 \n",
    "                    \n",
    "                    if time.time() - start_time >= detection_duration:\n",
    "                        print(f\"Initializing tracker with bbox: (x1={x1}, y1={y1}, w={w}, h={h})\")\n",
    "                        tracker = cv2.TrackerKCF_create()\n",
    "                        success = tracker.init(frame, (x1, y1, w, h))\n",
    "\n",
    "                        if not success:\n",
    "                            print(\"Tracker not initialized\")\n",
    "                        else:\n",
    "                            print(\"Tracker initialized successfully.\")\n",
    "                    else:\n",
    "                        print(\"Detecting with YOLO...\")\n",
    "                    \n",
    "                    x1, y1, x2, y2 = tuple(map(int, last_bbox.xyxy[0]))\n",
    "                    w = x2 - x1 \n",
    "                    h = y2 - y1                     \n",
    "                    face = frame[y1:y1+h, x1:x1+w]\n",
    "                    face_resized = cv2.resize(face, req_resolution) #,interpolation=cv2.INTER_AREA)\n",
    "                    out.write(face_resized)\n",
    "\n",
    "        else:\n",
    "            print(\"Tracking in progress...\")\n",
    "            success, bbox = tracker.update(frame)\n",
    "            \n",
    "            if success:\n",
    "                (x, y, w, h) = tuple(map(int, bbox))\n",
    "                # cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                face = frame[y:y+h, x:x+w]\n",
    "\n",
    "                face_resized = cv2.resize(face, req_resolution) #,interpolation=cv2.INTER_AREA)\n",
    "                out.write(face_resized)\n",
    "            else:\n",
    "                print(\"Tracker update failed.\")\n",
    "                tracker = None \n",
    "        cv2.imshow(f\"Tracking_Stream\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "    print(\"done cropping video\",os.path.basename(filename))\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id0_id16_0003.mp4'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n-face.pt\")\n",
    "\n",
    "\n",
    "for vid in celeb_df_real_vids:\n",
    "  op_vid=f\"cropped_celeb_df_real//{os.path.basename(vid)}\"\n",
    "  run_tracker(vid,model,op_vid)\n",
    "\n",
    "for vid in celeb_df_fake_vids:\n",
    "  op_vid=f\"cropped_celeb_df_fake//{os.path.basename(vid)}\"\n",
    "  run_tracker(vid,model,op_vid)\n",
    "\n",
    "for vid in dfdc_fake_vids:\n",
    "  op_vid=f\"dfdc_cropped_fake//{os.path.basename(vid)}\"\n",
    "  run_tracker(vid,model,op_vid)\n",
    "\n",
    "for vid in dfdc_real_vids:\n",
    "  op_vid=f\"dfdc_cropped_real//{os.path.basename(vid)}\"\n",
    "  run_tracker(vid,model,op_vid)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
